{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_feature_map_size(input_img_size, stride):\n",
    "    \"\"\"\n",
    "    Given an image size and stride of a network, computes the output feature map size.\n",
    "    \"\"\"\n",
    "    \n",
    "    input_size = np.asarray(input_img_size).astype(np.float)\n",
    "\n",
    "    feature_map_size = input_size / stride\n",
    "    \n",
    "    return np.floor(feature_map_size).astype(np.int)\n",
    "    \n",
    "\n",
    "class AnchorBoxGenerator():\n",
    "    \"\"\"\n",
    "    Anchor box generator class that takes care of generation of anchor\n",
    "    boxes for each element of resulted feature map. Feature map size is\n",
    "    computed given the input image size, it is equal to the the size of the input\n",
    "    image subsampled with a ```stirde``` parameter.\n",
    "    \n",
    "    The class accepts ```anchor_areas```, ```aspect_ratios``` parameters.\n",
    "    All possible pairs of these combinations are generated and result in\n",
    "    ```size(anchor_areas) * size(aspect_ratios) ``` anchor boxes for each\n",
    "    element of resulted feature map.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 anchor_areas=[128*128, 256*256, 512*512],\n",
    "                 aspect_ratios=[1/2., 1/1., 2/1.],\n",
    "                 stride=16\n",
    "                ):\n",
    "        \n",
    "        self.anchor_areas = anchor_areas\n",
    "        self.aspect_ratios = aspect_ratios\n",
    "        self.stride = stride\n",
    "        \n",
    "        \n",
    "    def get_anchor_boxes_sizes(self):\n",
    "        \"\"\"\n",
    "        Computes all pairs of ```anchor_areas``` and ```aspect_ratios``` parameters\n",
    "        resulting in bounding boxes of various sizes. Overall, the number of boxes is\n",
    "        equal to ```size(anchor_areas) * size(aspect_ratios) ```.\n",
    "        \"\"\"\n",
    "        \n",
    "        anchor_boxes_sizes = []\n",
    "        \n",
    "        for current_anchor_area in self.anchor_areas:\n",
    "            \n",
    "            for current_aspect_ratio in self.aspect_ratios:\n",
    "                \n",
    "                # Given:\n",
    "                # aspect_ratio = w / h\n",
    "                # anchor_area = w * h\n",
    "                # To find:\n",
    "                # w and h\n",
    "                # w = sqrt( aspect_ratio * anchor_area ) = sqrt( (w*w*h) / h ) = sqrt(w*w) = w\n",
    "                \n",
    "                w = math.sqrt( current_aspect_ratio * current_anchor_area )\n",
    "                h = current_anchor_area / w\n",
    "                \n",
    "                anchor_boxes_sizes.append((h, w))\n",
    "        \n",
    "        # Adding a dummy dimension here in order to easily use .repeat() later\n",
    "        return np.expand_dims( np.asarray(anchor_boxes_sizes), axis=0 )\n",
    "    \n",
    "    \n",
    "    def get_anchor_boxes_center_coordinates(self, input_size):\n",
    "        \"\"\"\n",
    "        Computes the coordinates of centers of bounding boxes of each element\n",
    "        of feature map with respect to the input image coordinate system.\n",
    "        We will need this to compute intersections of groundtruth boxes with \n",
    "        our generated anchor boxes which we will need to classify each anchor box\n",
    "        as a positive/negative/ambigious.\n",
    "        \"\"\"\n",
    "        \n",
    "        feature_map_height, feature_map_width = get_feature_map_size(input_size, stride=self.stride)\n",
    "\n",
    "        meshgrid_height, meshgrid_width = np.meshgrid(range(feature_map_height), range(feature_map_width))\n",
    "\n",
    "        # Getting coordinates of centers of all the grid cells of the feature map\n",
    "        anchor_coordinates_feature_map = zip(meshgrid_height.flatten(), meshgrid_width.flatten())\n",
    "        anchor_coordinates_feature_map = np.asarray( anchor_coordinates_feature_map )\n",
    "        anchor_coordinates_feature_map = anchor_coordinates_feature_map + 0.5\n",
    "\n",
    "        anchor_coordinates_input = anchor_coordinates_feature_map * self.stride\n",
    "        \n",
    "        return np.expand_dims( anchor_coordinates_input, axis=1 )\n",
    "        \n",
    "    \n",
    "    def get_anchor_boxes(self, input_size):\n",
    "        \"\"\"\n",
    "        Function that combines all the previous functions to compute all anchor boxes\n",
    "        with their coordinates with respect to the input image's coordinate system.\n",
    "        \n",
    "        Number of anchor boxes can be computed as:\n",
    "         ```size(anchor_areas) * size(aspect_ratios) * (input_height / stride) * (input_width / stride) ```\n",
    "        \"\"\"\n",
    "        \n",
    "        anchor_boxes_sizes = self.get_anchor_boxes_sizes()\n",
    "        anchor_boxes_center_coordinates = self.get_anchor_boxes_center_coordinates(input_size)\n",
    "        \n",
    "        anchor_boxes_sizes_number = anchor_boxes_sizes.shape[1]\n",
    "        anchor_boxes_center_coordinates_number = anchor_boxes_center_coordinates.shape[0]\n",
    "        \n",
    "        anchor_boxes_center_coordinates_repeated = anchor_boxes_center_coordinates.repeat(anchor_boxes_sizes_number, axis=1)\n",
    "        anchor_boxes_sizes_repeated =  anchor_boxes_sizes.repeat(anchor_boxes_center_coordinates_number, axis=0)\n",
    "        \n",
    "        anchor_boxes = np.dstack((anchor_boxes_center_coordinates_repeated, anchor_boxes_sizes_repeated))\n",
    "        \n",
    "        return anchor_boxes\n",
    "\n",
    "\n",
    "def center_xy_anchor_boxes_to_upper_left_xy(anchor_boxes):\n",
    "    \"\"\"\n",
    "    Converts the coordinates of the format\n",
    "    (x_center, y_center, width, height) to\n",
    "    (x_topleft, y_topleft, width, height)\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor_boxes_copy = anchor_boxes.copy()\n",
    "    anchor_boxes_copy_flattened = anchor_boxes_copy.reshape((-1, 4))\n",
    "    \n",
    "    for anchor_box in anchor_boxes_copy_flattened:\n",
    "        \n",
    "        anchor_box[0] = anchor_box[0] - anchor_box[2] / 2\n",
    "        anchor_box[1] = anchor_box[1] - anchor_box[3] / 2\n",
    "    \n",
    "    return anchor_boxes_copy_flattened.reshape(anchor_boxes_copy.shape)\n",
    "\n",
    "def convert_xywh_to_xyxy(bounding_box):\n",
    "    \"\"\"\n",
    "    Converts the coordinates of the format\n",
    "    (x_topleft, y_topleft, width, height) to\n",
    "    (x_topleft, y_topleft, x_bottomright, y_bottomright)\n",
    "    \"\"\"\n",
    "    \n",
    "    bounding_box = np.asarray(bounding_box).copy()\n",
    "    \n",
    "    bounding_box[2] = bounding_box[0] + bounding_box[2]\n",
    "    bounding_box[3] = bounding_box[1] + bounding_box[3]\n",
    "    \n",
    "    return bounding_box\n",
    "\n",
    "def draw_stride_grid_on_image(image, stride, grid_color=[0, 0, 0]):\n",
    "    \"\"\"\n",
    "    Draws a stride grid on the input image with a give stride.\n",
    "    Used to demonstrate regions in the input image that are associated\n",
    "    with respective elementes of subsampled feature map.\n",
    "    \"\"\"\n",
    "    img_with_grid = img.copy()\n",
    "    \n",
    "    # Modify the image to include the grid\n",
    "    img_with_grid[:,::stride,:] = grid_color\n",
    "    img_with_grid[::stride,:,:] = grid_color\n",
    "\n",
    "    return img_with_grid\n",
    "\n",
    "def draw_separate_grid_cell(image, x, y, stride, grid_color=[255, 255, 0]):\n",
    "    \"\"\"\n",
    "    Highlights a certain grid cell on the image. See the previous function\n",
    "    documentation for details.\n",
    "    \"\"\"\n",
    "    \n",
    "    img_with_grid = img.copy()\n",
    "    \n",
    "    img_with_grid[y*stride:(y+1)*stride, [x*stride, (x+1)*stride], :] = grid_color\n",
    "    img_with_grid[[y*stride, (y+1)*stride], x*stride:(x+1)*stride, :] = grid_color\n",
    "    \n",
    "    return img_with_grid\n",
    "\n",
    "def bboxes_ious(bboxes_group_1, bboxes_group_2):\n",
    "    \"\"\"\n",
    "    Computes the intersections over union metric between each\n",
    "    pair of boxes from group 1 and group 2.\n",
    "    \n",
    "    Also returns the coordinates of the intersection rectangle if\n",
    "    the intersection exists.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computing the bboxes of the intersections between\n",
    "    # each pair of boxes from group 1 and 2\n",
    "    top_left = np.maximum(bboxes_group_1[:,None , :2],\n",
    "                          bboxes_group_2[:, :2]).astype(np.float)\n",
    "\n",
    "    bottom_right = np.minimum(bboxes_group_1[:, None, 2:],\n",
    "                              bboxes_group_2[:, 2:])\n",
    "    \n",
    "    intersections_bboxes_xyxy = np.dstack((top_left, bottom_right))\n",
    "    \n",
    "    intersections_bboxes_width_height = np.clip( bottom_right - top_left, a_min=0, a_max=None)\n",
    "\n",
    "    intersections_bboxes_areas = intersections_bboxes_width_height[:, :, 0] * intersections_bboxes_width_height[:, :, 1]\n",
    "    \n",
    "    bboxes_group_1_areas = (bboxes_group_1[:,2]-bboxes_group_1[:,0]) * (bboxes_group_1[:,3]-bboxes_group_1[:,1])\n",
    "    bboxes_group_2_areas = (bboxes_group_2[:,2]-bboxes_group_2[:,0]) * (bboxes_group_2[:,3]-bboxes_group_2[:,1])\n",
    "    \n",
    "    ious = intersections_bboxes_areas / (bboxes_group_1_areas[:, None] + bboxes_group_2_areas - intersections_bboxes_areas)\n",
    "    \n",
    "    return ious, intersections_bboxes_xyxy\n",
    "    \n",
    "# Output stride of the network, change if you want a different one\n",
    "stride = 32\n",
    "\n",
    "# Loading the coco-like dataset file of PASCAL VOC 2012 detection\n",
    "coco_db = torchvision.datasets.CocoDetection(annFile='/home/daniil/projects/pascal/PASCAL_VOC/pascal_val2012.json',\n",
    "                                             root='/home/daniil/projects/pascal/dataset/VOCdevkit/VOC2012/JPEGImages/')    \n",
    "\n",
    "# Taking one predefine sample from the dataset\n",
    "img, annotations = coco_db[4700]\n",
    "\n",
    "# Getting the image and its size\n",
    "img = np.asarray(img)\n",
    "img_shape = img.shape[:2]\n",
    "\n",
    "# Getting the groundtruth bounding box\n",
    "ground_truth_bbox = annotations[3]['bbox']\n",
    "ground_truth_bbox_xyxy = convert_xywh_to_xyxy( ground_truth_bbox ).astype(np.float)\n",
    "ground_truth_bbox_xyxy = ground_truth_bbox_xyxy[None, :]\n",
    "\n",
    "\n",
    "feature_map_height, feature_map_width = get_feature_map_size(img_shape, stride=stride)\n",
    "\n",
    "img = draw_stride_grid_on_image(img, stride=stride)\n",
    "\n",
    "anchor_generator = AnchorBoxGenerator(stride=stride)\n",
    "\n",
    "anchor_boxes_different_areas_number = len(anchor_generator.anchor_areas)\n",
    "anchor_boxes_different_aspect_ratios_number = len(anchor_generator.aspect_ratios)\n",
    "\n",
    "anchor_boxes_centered = anchor_generator.get_anchor_boxes(input_size=img_shape)\n",
    "anchor_boxes_top_left = center_xy_anchor_boxes_to_upper_left_xy(anchor_boxes_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1aa311b723463ab62a7a0c29e41d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_anchors>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def display_anchors(x, y, anchor_area, anchor_aspect_ratio):\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1, figsize=(9, 6.9))\n",
    "    \n",
    "    # Drawing the feature map drid cells in the input image\n",
    "    image = draw_separate_grid_cell(img, x, y, stride)\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    spatial_position = x * feature_map_height + y\n",
    "    anchor_type = anchor_area * anchor_boxes_different_areas_number + anchor_aspect_ratio\n",
    "    \n",
    "    anchor_box = anchor_boxes_top_left[spatial_position, anchor_type, :].copy()\n",
    "    # converting h, w to x, y, basically just swapping values\n",
    "    anchor_box[:2] = anchor_box[1], anchor_box[0]\n",
    "    anchor_box[2:] = anchor_box[3], anchor_box[2]\n",
    "    \n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle(anchor_box[:2],\n",
    "                             anchor_box[2],\n",
    "                             anchor_box[3],\n",
    "                             linewidth=2,\n",
    "                             edgecolor='b',\n",
    "                             facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    x_anchor_box_center = anchor_box[0] + anchor_box[2] / 2\n",
    "    y_anchor_box_center = anchor_box[1] + anchor_box[3] / 2\n",
    "    \n",
    "    ax.plot(x_anchor_box_center, y_anchor_box_center, 'bs')\n",
    "    \n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle( ground_truth_bbox[:2],\n",
    "                             ground_truth_bbox[2],\n",
    "                             ground_truth_bbox[3],\n",
    "                             linewidth=2,\n",
    "                             edgecolor='r',\n",
    "                             facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    anchor_box_xyxy = convert_xywh_to_xyxy(anchor_box)\n",
    "    anchor_box_xyxy = anchor_box_xyxy[None, :]\n",
    "    \n",
    "    intersection_area, intersection_bbox = bboxes_ious(ground_truth_bbox_xyxy, anchor_box_xyxy)\n",
    "    intersection_bbox = intersection_bbox.squeeze()\n",
    "    \n",
    "    print(\"Intersection over union: \", intersection_area[0, 0])\n",
    "    \n",
    "    # display intersection area if intersection exists\n",
    "    if (intersection_area > 0).all():\n",
    "        \n",
    "        # Create a Rectangle patch\n",
    "        rect = patches.Rectangle( intersection_bbox[:2],\n",
    "                                 intersection_bbox[2] - intersection_bbox[0],\n",
    "                                 intersection_bbox[3] - intersection_bbox[1],\n",
    "                                 linewidth=2,\n",
    "                                 edgecolor='w',\n",
    "                                facecolor='none',\n",
    "                                hatch='\\\\')\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "    plt.show()    \n",
    "    \n",
    "\n",
    "\n",
    "spatial_position_widget = widgets.IntSlider(min=0,\n",
    "                                            max=feature_map_width - 1,\n",
    "                                            step=1,\n",
    "                                            value=10,\n",
    "                                            continuous_update=False)\n",
    "\n",
    "\n",
    "spatial_position_widget2 = widgets.IntSlider(min=0,\n",
    "                                             max=feature_map_height - 1,\n",
    "                                             step=1,\n",
    "                                             value=5,\n",
    "                                             continuous_update=False)\n",
    "\n",
    "\n",
    "\n",
    "areas_sqrt = map(lambda x: str(int(math.sqrt(x))) + '^2', anchor_generator.anchor_areas)\n",
    "anchor_area_slider_names_values_dict = OrderedDict(zip(areas_sqrt, range(anchor_boxes_different_areas_number)))\n",
    "\n",
    "\n",
    "anchor_area_widget = widgets.SelectionSlider(\n",
    "    options=anchor_area_slider_names_values_dict,\n",
    "    description='anchor area',\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "aspect_ratios_list_of_strings = map(lambda x: str(x), anchor_generator.aspect_ratios)\n",
    "\n",
    "\n",
    "anchor_aspect_slider_names_values_dict = OrderedDict(zip(aspect_ratios_list_of_strings, range(anchor_boxes_different_aspect_ratios_number)))\n",
    "\n",
    "\n",
    "anchor_aspect_widget = widgets.SelectionSlider(\n",
    "    options=anchor_aspect_slider_names_values_dict,\n",
    "    description='anchor aspect ratio',\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "\n",
    "interact(display_anchors,\n",
    "         x=spatial_position_widget,\n",
    "         y=spatial_position_widget2,\n",
    "         anchor_area=anchor_area_widget,\n",
    "         anchor_aspect_ratio=anchor_aspect_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
